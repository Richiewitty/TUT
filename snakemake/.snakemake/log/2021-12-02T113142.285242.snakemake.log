Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                      count    min threads    max threads
---------------------  -------  -------------  -------------
convert_to_upper_case        2              1              1
total                        2              1              1

Select jobs to execute...

[Thu Dec  2 11:31:44 2021]
rule convert_to_upper_case:
    input: a.txt
    output: a.upper.txt
    jobid: 0
    reason: Missing output files: a.upper.txt
    wildcards: sample=a
    resources: tmpdir=/tmp


        tr [a-z] [A-Z] < a.txt > a.upper.txt
        
[Thu Dec  2 11:31:44 2021]
Finished job 0.
1 of 2 steps (50%) done
Select jobs to execute...

[Thu Dec  2 11:31:44 2021]
rule convert_to_upper_case:
    input: b.txt
    output: b.upper.txt
    jobid: 1
    reason: Missing output files: b.upper.txt
    wildcards: sample=b
    resources: tmpdir=/tmp


        tr [a-z] [A-Z] < b.txt > b.upper.txt
        
[Thu Dec  2 11:31:44 2021]
Finished job 1.
2 of 2 steps (100%) done
Complete log: /home/dinesh/TUT/workshop-reproducible-research/tutorials/snakemake/.snakemake/log/2021-12-02T113142.285242.snakemake.log
